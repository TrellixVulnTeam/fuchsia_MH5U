// Copyright 2019 The Fuchsia Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#version 460

//
// RASTERS RECLAIM
//
//
// FIXME(allanmac): use one inclusive bitcount
//
#extension GL_EXT_debug_printf : enable

//
//
//
#extension GL_GOOGLE_include_directive : require
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_ballot : require

//
//
//
#include "config.h"
#include "push.h"

//
//
//
layout(local_size_x = SPN_DEVICE_RASTERS_RECLAIM_WORKGROUP_SIZE) in;

//
// Push constants
//
SPN_PUSH_LAYOUT_RECLAIM();

//
// Buffer references
//
SPN_BUFFER_DEFINE_RECLAIM(readonly);
SPN_BUFFER_DEFINE_BLOCK_POOL_IDS(readwrite, writeonly);
SPN_BUFFER_DEFINE_BLOCK_POOL_BLOCKS(readonly);
SPN_BUFFER_DEFINE_BLOCK_POOL_HOST_MAP(readonly);

//
// Local defines
//
#define SPN_RASTERS_RECLAIM_SUBGROUP_SIZE (1 << SPN_DEVICE_RASTERS_RECLAIM_SUBGROUP_SIZE_LOG2)

#define SPN_RASTERS_RECLAIM_SUBGROUPS                                                              \
  (SPN_DEVICE_RASTERS_RECLAIM_WORKGROUP_SIZE / SPN_RASTERS_RECLAIM_SUBGROUP_SIZE)

//
// Block expansion size
//
#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND_SIZE                                                      \
  (SPN_BLOCK_POOL_BLOCK_QWORDS / SPN_RASTERS_RECLAIM_SUBGROUP_SIZE)

//
// Block expansion
//
#if (SPN_RASTERS_RECLAIM_BLOCK_EXPAND_SIZE == 1)

#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_1()
#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST 0

#elif (SPN_RASTERS_RECLAIM_BLOCK_EXPAND_SIZE == 2)

#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_2()
#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST 1

#elif (SPN_RASTERS_RECLAIM_BLOCK_EXPAND_SIZE == 4)

#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_4()
#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST 3

#elif (SPN_RASTERS_RECLAIM_BLOCK_EXPAND_SIZE == 8)

#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_8()
#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST 7

#elif (SPN_RASTERS_RECLAIM_BLOCK_EXPAND_SIZE == 16)

#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_16()
#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST 15

#elif (SPN_RASTERS_RECLAIM_BLOCK_EXPAND_SIZE == 32)

#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_32()
#define SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST 31

#else
#error "Define larger expansion!"
#endif

//
// Broadcast to a compile-time lane
//
#define SPN_RASTERS_RECLAIM_BROADCAST(E, O, I)                                                     \
  subgroupBroadcast(E, O - I * SPN_RASTERS_RECLAIM_SUBGROUP_SIZE)

//
// A single workgroup reclaims an array of handles.
//
// FIXME(allanmac): move these ids into an SMEM array and let subgroups
// grab the next unreclaimed id.
//
void
main()
{
  //
  // This is a subgroup/warp-centric kernel.
  //
  // Which subgroup in the grid is this?
  //
  // clang-format off
#if (SPN_RASTERS_RECLAIM_SUBGROUPS == 1)
  SPN_SUBGROUP_UNIFORM uint32_t sid = gl_WorkGroupID.x;
#else
  SPN_SUBGROUP_UNIFORM uint32_t sid = gl_WorkGroupID.x * SPN_RASTERS_RECLAIM_SUBGROUPS + gl_SubgroupID;

  // Return from any empty subgroups
  if (sid >= push.ring_span)
    {
      return;
    }
#endif
  // clang-format on

  //
  // Which slot in the ring?
  //
  uint32_t reclaim_idx = push.ring_head + sid;

  if (reclaim_idx >= push.ring_size)
    {
      reclaim_idx -= push.ring_size;
    }

  // define reclaim bufref
  SPN_BUFREF_DEFINE(SPN_BUFFER_TYPE(reclaim), reclaim, push.devaddr_reclaim);

  // get host raster id
  SPN_SUBGROUP_UNIFORM const uint32_t raster_h = reclaim.extent[reclaim_idx];

  // define host map bufref
  SPN_BUFREF_DEFINE(SPN_BUFFER_TYPE(block_pool_host_map),
                    bp_host_map,
                    push.devaddr_block_pool_host_map);

  // get the raster header block from the map
  SPN_SUBGROUP_UNIFORM uint32_t node_id = bp_host_map.extent[raster_h];

  //
  // Load the first half of the head block into registers and
  // start reclaiming blocks.
  //
  // The layout of a raster node is optimized for reclamation:
  //
  //   union {
  //     u32vec2    qwords[block_qwords];
  //     struct {
  //       uint32_t dwords_lo[block_qwords];
  //       uint32_t dwords_hi[block_qwords];
  //     };
  //   };
  //

  //
  // load "lo" half of head
  //
  const uint32_t h_idx = node_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS + gl_SubgroupInvocationID;

  // define block pool blocks bufref
  SPN_BUFREF_DEFINE(SPN_BUFFER_TYPE(block_pool_blocks), bp_blocks, push.devaddr_block_pool_blocks);

#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  uint32_t h##I = bp_blocks.extent[h_idx + I * SPN_RASTERS_RECLAIM_SUBGROUP_SIZE];

  SPN_RASTERS_RECLAIM_BLOCK_EXPAND();

  //
  // pick out count.blocks the header
  //
  SPN_SUBGROUP_UNIFORM uint32_t count_blocks;

#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  if (SPN_RASTER_HEAD_ELEM_IN_RANGE(SPN_RASTERS_RECLAIM_SUBGROUP_SIZE,                             \
                                    SPN_RASTER_HEAD_LO_OFFSET_BLOCKS,                              \
                                    I))                                                            \
    {                                                                                              \
      count_blocks = SPN_RASTERS_RECLAIM_BROADCAST(h##I, SPN_RASTER_HEAD_LO_OFFSET_BLOCKS, I);     \
    }

  SPN_RASTERS_RECLAIM_BLOCK_EXPAND();

  //
  // acquire a span in the block pool ids ring for reclaimed ids
  //
  uint32_t bp_ids_writes = 0;

  // define block pool ids bufref
  SPN_BUFREF_DEFINE(SPN_BUFFER_TYPE(block_pool_ids), bp_ids, push.devaddr_block_pool_ids);

  if (gl_SubgroupInvocationID == 0)
    {
      bp_ids_writes = atomicAdd(bp_ids.atomics[SPN_BLOCK_POOL_ATOMICS_WRITES], count_blocks);
    }

  SPN_SUBGROUP_UNIFORM uint32_t       bp_ids_base = subgroupBroadcast(bp_ids_writes, 0);
  SPN_SUBGROUP_UNIFORM const uint32_t bp_ids_max  = bp_ids_base + count_blocks;

  //
  // blindly swap the current node id with the "next" id
  //
  {
    SPN_SUBGROUP_UNIFORM const uint32_t node_next =
      subgroupBroadcast(SPN_GLSL_CONCAT(h, SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST),
                        SPN_RASTERS_RECLAIM_SUBGROUP_SIZE - 1);

    if (gl_SubgroupInvocationID == SPN_RASTERS_RECLAIM_SUBGROUP_SIZE - 1)
      {
        SPN_GLSL_CONCAT(h, SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST) = node_id;
      }

    node_id = node_next;
  }

//
// invalidate all header components
//
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  if (!SPN_RASTER_HEAD_ENTIRELY_HEADER(SPN_RASTERS_RECLAIM_SUBGROUP_SIZE, I))                      \
    {                                                                                              \
      if (SPN_RASTER_HEAD_PARTIALLY_HEADER(SPN_RASTERS_RECLAIM_SUBGROUP_SIZE, I))                  \
        {                                                                                          \
          if (SPN_RASTER_HEAD_IS_HEADER(SPN_RASTERS_RECLAIM_SUBGROUP_SIZE, I))                     \
            {                                                                                      \
              h##I = SPN_TTXK_INVALID[0];                                                          \
            }                                                                                      \
        }                                                                                          \
    }

  SPN_RASTERS_RECLAIM_BLOCK_EXPAND();

//
// find ring index of all blocks and store
//
// FIXME(allanmac): this is NOT COALESCED -- fix this
//
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  if (!SPN_RASTER_HEAD_ENTIRELY_HEADER(SPN_RASTERS_RECLAIM_SUBGROUP_SIZE, I))                      \
    {                                                                                              \
      const bool     is_block     = SPN_BLOCK_ID_IS_BLOCK(h##I);                                   \
      const u32vec4  block_ballot = subgroupBallot(is_block);                                      \
      const uint32_t bp_ids_off   = bp_ids_base + subgroupBallotExclusiveBitCount(block_ballot);   \
                                                                                                   \
      if (is_block)                                                                                \
        {                                                                                          \
          const uint32_t ids_idx = bp_ids_off & push.bp_mask;                                      \
                                                                                                   \
          bp_ids.ids[ids_idx] = SPN_TTXK_LO_GET_TTXB_ID(h##I);                                     \
        }                                                                                          \
                                                                                                   \
      bp_ids_base += subgroupBallotBitCount(block_ballot);                                         \
                                                                                                   \
      if (bp_ids_base == bp_ids_max)                                                               \
        {                                                                                          \
          return;                                                                                  \
        }                                                                                          \
    }

  SPN_RASTERS_RECLAIM_BLOCK_EXPAND();

  //
  // process next node
  //
  while (true)
    {
      //
      // load entire node
      //
      const uint32_t n_idx = node_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS + gl_SubgroupInvocationID;

#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  uint32_t n##I = bp_blocks.extent[n_idx + I * SPN_RASTERS_RECLAIM_SUBGROUP_SIZE];

      SPN_RASTERS_RECLAIM_BLOCK_EXPAND();

      //
      // blindly swap the current node id with the "next" id
      //
      {
        SPN_SUBGROUP_UNIFORM const uint32_t node_next =
          subgroupBroadcast(SPN_GLSL_CONCAT(n, SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST),
                            SPN_RASTERS_RECLAIM_SUBGROUP_SIZE - 1);

        if (gl_SubgroupInvocationID == SPN_RASTERS_RECLAIM_SUBGROUP_SIZE - 1)
          {
            SPN_GLSL_CONCAT(n, SPN_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST) = node_id;
          }

        node_id = node_next;
      }

      //
      // find ring index of all blocks and store
      //
      // FIXME(allanmac): this is NOT COALESCED -- fix this
      //
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  {                                                                                                \
    const bool     is_block     = SPN_BLOCK_ID_IS_BLOCK(n##I);                                     \
    const u32vec4  block_ballot = subgroupBallot(is_block);                                        \
    const uint32_t bp_ids_off   = bp_ids_base + subgroupBallotExclusiveBitCount(block_ballot);     \
                                                                                                   \
    if (is_block)                                                                                  \
      {                                                                                            \
        const uint32_t ids_idx = bp_ids_off & push.bp_mask;                                        \
                                                                                                   \
        bp_ids.ids[ids_idx] = SPN_TTXK_LO_GET_TTXB_ID(n##I);                                       \
      }                                                                                            \
                                                                                                   \
    bp_ids_base += subgroupBallotBitCount(block_ballot);                                           \
                                                                                                   \
    if (bp_ids_base == bp_ids_max) /* equality test works with ring wraparound */                  \
      {                                                                                            \
        return;                                                                                    \
      }                                                                                            \
  }

      SPN_RASTERS_RECLAIM_BLOCK_EXPAND();
    }
}

//
//
//
