// Copyright 2019 The Fuchsia Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#version 460

//
// FIXME(allanmac): use one inclusive bitcount
//

#extension GL_GOOGLE_include_directive : require
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_ballot : require

//
//
//

#include "spn_config.h"
#include "vk_layouts.h"

//
//
//

layout(local_size_x = SPN_DEVICE_PATHS_RECLAIM_WORKGROUP_SIZE) in;

//
//
//

SPN_VK_GLSL_DECL_KERNEL_PATHS_RECLAIM();

//
// CONSTANTS
//

#define SPN_PATHS_RECLAIM_SUBGROUP_SIZE (1 << SPN_DEVICE_PATHS_RECLAIM_SUBGROUP_SIZE_LOG2)

#define SPN_PATHS_RECLAIM_SUBGROUPS                                                                \
  (SPN_DEVICE_PATHS_RECLAIM_WORKGROUP_SIZE / SPN_PATHS_RECLAIM_SUBGROUP_SIZE)

//
// BLOCK EXPANSION
//

#define SPN_PATHS_RECLAIM_BLOCK_EXPAND_SIZE                                                        \
  (SPN_BLOCK_POOL_BLOCK_DWORDS / SPN_PATHS_RECLAIM_SUBGROUP_SIZE)

//
//
//

#if (SPN_PATHS_RECLAIM_BLOCK_EXPAND_SIZE == 1)

#define SPN_PATHS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_1()
#define SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST 0

#elif (SPN_PATHS_RECLAIM_BLOCK_EXPAND_SIZE == 2)

#define SPN_PATHS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_2()
#define SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST 1

#elif (SPN_PATHS_RECLAIM_BLOCK_EXPAND_SIZE == 4)

#define SPN_PATHS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_4()
#define SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST 3
#elif (SPN_PATHS_RECLAIM_BLOCK_EXPAND_SIZE == 8)

#define SPN_PATHS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_8()
#define SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST 7

#elif (SPN_PATHS_RECLAIM_BLOCK_EXPAND_SIZE == 16)

#define SPN_PATHS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_16()
#define SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST 15

#elif (SPN_PATHS_RECLAIM_BLOCK_EXPAND_SIZE == 32)

#define SPN_PATHS_RECLAIM_BLOCK_EXPAND() SPN_EXPAND_32()
#define SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST 31

#endif

//
// BROADCAST TO A COMPILE-TIME LANE
//

#define SPN_PATHS_RECLAIM_BROADCAST(E, O, I)                                                       \
  subgroupBroadcast(E, O - I * SPN_PATHS_RECLAIM_SUBGROUP_SIZE)

//
// A single workgroup reclaims an array of handles.
//
// FIXME(allanmac): move these ids into an SMEM array and let subgroups
// grab the next unreclaimed id.
//

void
main()
{
  //
  // This is a subgroup/warp-centric kernel.
  //
  // Which subgroup in the grid is this?
  //
#if (SPN_PATHS_RECLAIM_SUBGROUPS == 1)

  SPN_SUBGROUP_UNIFORM uint sid = gl_WorkGroupID.x;

#else

  SPN_SUBGROUP_UNIFORM uint sid = gl_WorkGroupID.x * SPN_PATHS_RECLAIM_SUBGROUPS + gl_SubgroupID;

  // this an empty subgroup?
  if (sid >= ring_span)
    return;

#endif

  uint reclaim_idx = ring_head + sid;

  if (reclaim_idx >= ring_size)
    reclaim_idx -= ring_size;

  // get host path id
  SPN_SUBGROUP_UNIFORM const uint path_h = ring[reclaim_idx];

  // get the path header block from the map
  SPN_SUBGROUP_UNIFORM uint node_id = bp_host_map[path_h];

  //
  // load the entire head block into registers and start
  // reclaiming blocks
  //
  const uint h_idx = node_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS + gl_SubgroupInvocationID;

#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L) uint h##I = bp_blocks[h_idx + I * SPN_PATHS_RECLAIM_SUBGROUP_SIZE];

  SPN_PATHS_RECLAIM_BLOCK_EXPAND();

  //
  // pick out count.blocks from the header
  //
  SPN_SUBGROUP_UNIFORM uint count_blocks;

#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  if (SPN_PATH_HEAD_ELEM_IN_RANGE(SPN_PATHS_RECLAIM_SUBGROUP_SIZE,                                 \
                                  SPN_PATH_HEAD_OFFSET_BLOCKS,                                     \
                                  I))                                                              \
    {                                                                                              \
      count_blocks = SPN_PATHS_RECLAIM_BROADCAST(h##I, SPN_PATH_HEAD_OFFSET_BLOCKS, I);            \
    }

  SPN_PATHS_RECLAIM_BLOCK_EXPAND();

  //
  // acquire a span in the block pool ids ring for reclaimed ids
  //
  uint bp_ids_writes = 0;

  if (gl_SubgroupInvocationID == 0)
    {
      bp_ids_writes = atomicAdd(bp_atomics[SPN_BLOCK_POOL_ATOMICS_WRITES], count_blocks);
    }

  SPN_SUBGROUP_UNIFORM uint       bp_ids_base = subgroupBroadcast(bp_ids_writes, 0);
  SPN_SUBGROUP_UNIFORM const uint bp_ids_max  = bp_ids_base + count_blocks;

  //
  // invalidate all header components
  //
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  if (!SPN_PATH_HEAD_ENTIRELY_HEADER(SPN_PATHS_RECLAIM_SUBGROUP_SIZE, I))                          \
    {                                                                                              \
      if (SPN_PATH_HEAD_PARTIALLY_HEADER(SPN_PATHS_RECLAIM_SUBGROUP_SIZE, I))                      \
        {                                                                                          \
          if (SPN_PATH_HEAD_IS_HEADER(SPN_PATHS_RECLAIM_SUBGROUP_SIZE, I))                         \
            {                                                                                      \
              h##I = SPN_TAGGED_BLOCK_ID_INVALID;                                                  \
            }                                                                                      \
        }                                                                                          \
    }

  SPN_PATHS_RECLAIM_BLOCK_EXPAND();

  //
  // shift away all tags
  //
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  if (!SPN_PATH_HEAD_ENTIRELY_HEADER(SPN_PATHS_RECLAIM_SUBGROUP_SIZE, I))                          \
    {                                                                                              \
      h##I = SPN_TAGGED_BLOCK_ID_GET_ID(h##I);                                                     \
    }

  SPN_PATHS_RECLAIM_BLOCK_EXPAND();

  //
  // blindly swap the current node id with the "next" id
  //
  {
    SPN_SUBGROUP_UNIFORM const uint node_next =
      subgroupBroadcast(SPN_GLSL_CONCAT(h, SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST),
                        SPN_PATHS_RECLAIM_SUBGROUP_SIZE - 1);

    if (gl_SubgroupInvocationID == SPN_PATHS_RECLAIM_SUBGROUP_SIZE - 1)
      {
        SPN_GLSL_CONCAT(h, SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST) = node_id;
      }

    node_id = node_next;
  }

  //
  // find ring index of all blocks and store -- FIXME -- NOT COALESCED
  //
  // FIXME(allanmac): this is NOT COALESCED -- fix this
  //
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  if (!SPN_PATH_HEAD_ENTIRELY_HEADER(SPN_PATHS_RECLAIM_SUBGROUP_SIZE, I))                          \
    {                                                                                              \
      const bool  is_block     = SPN_BLOCK_ID_IS_BLOCK(h##I);                                      \
      const uvec4 block_ballot = subgroupBallot(is_block);                                         \
      const uint  bp_ids_off   = bp_ids_base + subgroupBallotExclusiveBitCount(block_ballot);      \
                                                                                                   \
      if (is_block)                                                                                \
        {                                                                                          \
          bp_ids[bp_ids_off & bp_mask] = h##I;                                                     \
        }                                                                                          \
                                                                                                   \
      bp_ids_base += subgroupBallotBitCount(block_ballot);                                         \
                                                                                                   \
      if (bp_ids_base == bp_ids_max)                                                               \
        {                                                                                          \
          return;                                                                                  \
        }                                                                                          \
    }

  SPN_PATHS_RECLAIM_BLOCK_EXPAND();

  //
  // process next node
  //
  while (true)
    {
      //
      // load entire node
      //
      const uint n_idx = node_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS + gl_SubgroupInvocationID;

#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L) uint n##I = bp_blocks[n_idx + I * SPN_PATHS_RECLAIM_SUBGROUP_SIZE];

      SPN_PATHS_RECLAIM_BLOCK_EXPAND();

      //
      // shift away all tags
      //
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L) n##I = SPN_TAGGED_BLOCK_ID_GET_ID(n##I);

      SPN_PATHS_RECLAIM_BLOCK_EXPAND();

      //
      // blindly swap the current node id with the "next" id
      //
      {
        SPN_SUBGROUP_UNIFORM const uint node_next =
          subgroupBroadcast(SPN_GLSL_CONCAT(n, SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST),
                            SPN_PATHS_RECLAIM_SUBGROUP_SIZE - 1);

        if (gl_SubgroupInvocationID == SPN_PATHS_RECLAIM_SUBGROUP_SIZE - 1)
          {
            SPN_GLSL_CONCAT(n, SPN_PATHS_RECLAIM_BLOCK_EXPAND_I_LAST) = node_id;
          }

        node_id = node_next;
      }

      //
      // find ring index of all blocks and store
      //
      // FIXME(allanmac): this is NOT COALESCED -- fix this
      //
#undef SPN_EXPAND_X
#define SPN_EXPAND_X(I, N, P, L)                                                                   \
  {                                                                                                \
    const bool  is_block     = SPN_BLOCK_ID_IS_BLOCK(n##I);                                        \
    const uvec4 block_ballot = subgroupBallot(is_block);                                           \
    const uint  bp_ids_off   = bp_ids_base + subgroupBallotExclusiveBitCount(block_ballot);        \
                                                                                                   \
    if (is_block)                                                                                  \
      {                                                                                            \
        bp_ids[bp_ids_off & bp_mask] = n##I;                                                       \
      }                                                                                            \
                                                                                                   \
    bp_ids_base += subgroupBallotBitCount(block_ballot);                                           \
                                                                                                   \
    if (bp_ids_base == bp_ids_max)                                                                 \
      {                                                                                            \
        return;                                                                                    \
      }                                                                                            \
  }

      SPN_PATHS_RECLAIM_BLOCK_EXPAND();
    }
}

//
//
//
