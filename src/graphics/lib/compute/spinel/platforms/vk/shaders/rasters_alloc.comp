// Copyright 2019 The Fuchsia Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#version 460

//
// RASTERS ALLOC
//

#extension GL_GOOGLE_include_directive : require
#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_KHR_shader_subgroup_ballot : require

//
//
//

#include "spn_config.h"
#include "vk_layouts.h"

//
//
//

layout(local_size_x = SPN_DEVICE_RASTERS_ALLOC_WORKGROUP_SIZE) in;

//
//
//

SPN_VK_GLSL_DECL_KERNEL_RASTERS_ALLOC();

//
//
//

#define SPN_RASTERS_ALLOC_SUBGROUP_SIZE (1 << SPN_DEVICE_RASTERS_ALLOC_SUBGROUP_SIZE_LOG2)

//
// There is a fixed-size meta table per raster cohort that we use to
// peform a mostly coalesced sizing and allocation of blocks.
//
// This code is simple and fast and each lane runs in isolation except
// for a atomic operation reducing subgroup prefix sum.
//

void
main()
{
  // access to the meta extent is linear
  const bool is_active = gl_GlobalInvocationID.x < raster_span;

  // raster index
  uint raster_idx = raster_head + gl_GlobalInvocationID.x;

  if (raster_idx >= raster_size)
    {
      raster_idx -= raster_size;
    }

  //
  // active cohorts store the computed info directly to the header block
  //
  uint  raster_h;
  uvec4 header_lo;
  uint  blocks;
  uint  extra = 0;

  if (is_active)
    {
      // load raster_id as early as possible
      raster_h = raster_ids[raster_idx];

      // load meta_in
      blocks                                     = ttrks_meta.blocks[gl_GlobalInvocationID.x];
      header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTSKS] = ttrks_meta.ttrks[gl_GlobalInvocationID.x];
      header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTPKS] = ttrks_meta.ttpks[gl_GlobalInvocationID.x];

      // how many blocks will the ttpb vectors consume?
      extra = (header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTPKS] +  //
               SPN_BLOCK_POOL_SUBBLOCKS_PER_BLOCK - 1) /     //
              SPN_BLOCK_POOL_SUBBLOCKS_PER_BLOCK;            //

      // total keys
      const uint ttxks = header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTSKS] +  //
                         header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTPKS];   //

      //
      // how many extra blocks do we need to store all the keys in a
      // head and nodes?
      //
      // note: the "-1" is due to the final qword being used to point to
      // the next node
      //
      const uint ttxks_hn_pad = SPN_RASTER_HEAD_QWORDS + ttxks;
      const uint ttxks_hn_ru  = ttxks_hn_pad + SPN_RASTER_NODE_QWORDS - 2;
      const uint ttxks_hn     = ttxks_hn_ru / (SPN_RASTER_NODE_QWORDS - 1);

      // increment extra
      extra += ttxks_hn;

      // how many nodes trail the head?
      header_lo[SPN_RASTER_HEAD_LO_OFFSET_NODES] = ttxks_hn - 1;

      // update blocks
      blocks += extra;
    }

  //
  // allocate blocks from block pool
  //
  // first perform a prefix sum on the subgroup to reduce atomic
  // operation traffic
  //
  // this idiom can be pushed further to operate across a workgroup or
  // operated on vectors.
  //
  const uint inc          = subgroupInclusiveAdd(extra);
  uint       bp_ids_reads = 0;

  // last lane performs the block pool alloc with an atomic increment
  if (gl_SubgroupInvocationID == SPN_RASTERS_ALLOC_SUBGROUP_SIZE - 1)
    {
      bp_ids_reads = atomicAdd(bp_atomics[SPN_BLOCK_POOL_ATOMICS_READS], inc);
    }

  // broadcast block pool base to all lanes
  SPN_SUBGROUP_UNIFORM
  const uint bp_ids_base = subgroupBroadcast(bp_ids_reads,  //
                                             SPN_RASTERS_ALLOC_SUBGROUP_SIZE - 1);

  //
  // store meta header
  //
  if (is_active)
    {
      // exclusive
      const uint exc = inc - extra;

      // update block pool reads base for each lane
      const uint reads = bp_ids_base + exc;

      // get block_id of each raster head
      const uint head_block_id = bp_ids[reads & bp_mask];

      // update map
      bp_host_map[raster_h] = head_block_id;

      //
      // The layout of allocated blocks is as follows:
      //
      //   ... | HEAD(1) | NODES(0+) | TTPB(0+) | ...
      //
      // Unlike previous Spinel implementations, TTPK keys immediately
      // follow TTSK keys.  The starting index of the TTPK keys in the
      // head or nodes is recorded in the raster header.
      //
      const uint pk0_pad = SPN_RASTER_HEAD_QWORDS +  //
                           header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTSKS];

      uint       pk0_node = pk0_pad / (SPN_RASTER_NODE_QWORDS - 1);
      const uint pk0_base = pk0_node * (SPN_RASTER_NODE_QWORDS - 1);
      uint       pk0_off  = pk0_pad - pk0_base;

      //
      // NOTE(allanmac): If there are any TTSK keys and if there are
      // zero TTPK keys then adjust for the special case where there
      // are (SPN_RASTER_NODE_QWORDS - 1) TTSK keys in the final
      // node.
      //
      if ((pk0_off == 0) &&  //
          (header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTPKS] == 0) &&
          (header_lo[SPN_RASTER_HEAD_LO_OFFSET_TTSKS] != 0))
        {
          pk0_node -= 1;
          pk0_off = SPN_RASTER_NODE_QWORDS - 1;
        }

      const uint pk0_reads     = reads + pk0_node;
      const uint pk0_block_id  = bp_ids[pk0_reads & bp_mask];
      const uint pk0_node_base = pk0_block_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS;

      //
      // save the ttrk and ttpk reads
      //
      ttrks_meta.alloc[gl_GlobalInvocationID.x] = uvec2(reads, pk0_reads);

      //
      // save the absolute block pool index of the first TTPK
      //
      // NOTE(allanmac): if there were zero TTPK keys then
      //
      header_lo[SPN_RASTER_HEAD_LO_OFFSET_PKIDX] = pk0_node_base + pk0_off;

      //
      // Write out uvec4 and uint to header resulting in this:
      //
      //   raster head block
      //   {
      //     struct spn_raster_header.lo
      //     {
      //       uint32_t nodes;   // # of nodes  -- not including header
      //       uint32_t ttsks;   // # of ttsks
      //       uint32_t ttpks;   // # of ttpks
      //       uint32_t pkidx;   // block pool dword of first ttpk.lo
      //       uint32_t blocks;  // # of blocks -- head+node+skb+pkb
      //
      //       ... uninitialized ...
      //     }
      //     ...
      //   }
      //
      // NOTE(allanmac): We're explicitly writing a second uvec4 because
      // GLSL appears to be confused by the block pool descriptor
      // aliasing (which is technically illegal).  It's likely a
      // spirv-opt or glslangValidator error.  Once buffer references
      // are available, we can write this the correct way.
      //
      const uint raster_head_base = head_block_id * SPN_BLOCK_POOL_SUBBLOCK_OWORDS;

      bp_blocks_uvec4[raster_head_base] = header_lo;

      //
      // a smart compiler will reduce this to a dword store
      //
      uvec4 header_dword5;

      header_dword5[0] = blocks;

      bp_blocks_uvec4[raster_head_base + 1] = header_dword5;
    }
}

//
//
//
